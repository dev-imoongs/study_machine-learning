#!/usr/bin/env python
# coding: utf-8

# ### Mean Shift (í‰ê·  ì´ë™)
# - ë°ì´í„° í¬ì¸íŠ¸ì˜ ë°€ì§‘ëœ ì˜ì—­ì„ ì°¾ìœ¼ë ¤ê³  ì‹œë„í•˜ëŠ” ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
# > ğŸ“Œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì•Œê³ ë¦¬ì¦˜ì´ë€, ê³ ì • ì‚¬ì´ì¦ˆì˜ ìœˆë„ìš°ê°€ ì´ë™í•˜ë©´ì„œ ìœˆë„ìš° ë‚´ì— ìˆëŠ” ë°ì´í„°ë¥¼ ì´ìš©í•´ ë¬¸ì œë¥¼ í’€ì´í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
# > - ì¼ì • ë²”ìœ„ì˜ ê°’ì„ ë¹„êµí•  ë•Œ ì‚¬ìš©í•˜ë©´ ë§¤ìš° ìœ ìš©í•˜ë©°, ìµœì†Œí•œì˜ ê³„ì‚°ìœ¼ë¡œ ë‹¤ìŒ ë°°ì—´ì˜ í•©ì„ êµ¬í•˜ëŠ” ë°©ì‹ì´ë‹¤.
# > - ì´ì „ ë°°ì—´ì˜ ì²« ë²ˆì§¸ ì›ì†Œë¥¼ ë¹¼ê³  ë‹¤ìŒì— ë“¤ì–´ì˜¬ ì›ì†Œë¥¼ ë”í•´ì£¼ëŠ” ê²ƒì´ ìµœì†Œí•œì˜ ê³„ì‚°ìœ¼ë¡œ ë‹¤ìŒ ë°°ì—´ì˜ í•©ì„ êµ¬í•˜ëŠ” ë°©ë²•ì´ë‹¤.
# - ê° êµ°ì§‘(í´ëŸ¬ìŠ¤í„°)ì˜ ì¤‘ì‹¬ì ì„ ì°¾ëŠ” ê²ƒì´ ëª©í‘œì´ë©°, ì¤‘ì‹¬ì  í›„ë³´ë¥¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë‚´ ì ë“¤ì˜ í‰ê· ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•œë‹¤.
# <img src="./images/mean_shift01.gif" width="200" style="margin-left:0">
# 
# - K-í‰ê·  í´ëŸ¬ìŠ¤í„°ë§ê³¼ ë‹¬ë¦¬ ìë™ìœ¼ë¡œ ì¤‘ì‹¬ì ì„ ë°œê²¬í•˜ê¸° ë•Œë¬¸ì— í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ì •í•´ë†“ì„ í•„ìš”ê°€ ì—†ë‹¤.
# <div style="display: flex">
#     <div>
#         <img src="./images/mean_shift02.gif" width="300" style="margin-left:0">
#     </div>
#     <div>
#         <img src="./images/mean_shift03.gif" width="400" style="margin-left:0">
#     </div>
# </div>
# 
# ##### KDE (Kernel Density Estimation), ì»¤ë„ ë°€ë„ ì¶”ì •
# - ì»¤ë„ í•¨ìˆ˜ë¥¼ í†µí•´ í™•ë¥  ë°€ë„ í•¨ìˆ˜(Probability Density Function)ë¥¼ ì¶”ì •í•˜ëŠ” ë°©ë²•ìœ¼ë¡œì„œ ëŒ€í‘œì ìœ¼ë¡œ ê°€ìš°ì‹œì•ˆ ë¶„í¬ í•¨ìˆ˜(ì •ê·œ ë¶„í¬ í•¨ìˆ˜)ê°€ ì‚¬ìš©ëœë‹¤.
# - ë°ì´í„° í¬ì¸íŠ¸ë“¤(ì¤‘ì‹¬ì )ì´ ë°ì´í„° ë¶„í¬ê°€ ë†’ì€ ê³³ìœ¼ë¡œ ì´ë™í•˜ë©´ì„œ êµ°ì§‘í™”ë¥¼ ìˆ˜í–‰í•œë‹¤.
# > - K: ì»¤ë„ í•¨ìˆ˜
# > - x: í™•ë¥  ë³€ìˆ˜ ë°ì´í„°
# > - x<sub>i</sub>: ê´€ì¸¡ ë°ì´í„°
# > - h: ëŒ€ì—­í­(bandwidth)
# <img src="./images/mean_shift04.png" width="400" style="margin-left:10px">
# <img src="./images/mean_shift05.png" width="400" style="margin-left:10px; margin-bottom: 20px">
# > - ëŒ€ì—­í­ì´ í´ ìˆ˜ë¡ ê°œë³„ ì»¤ë„ í•¨ìˆ˜ì˜ ì˜í–¥ë ¥ì´ ì‘ì–´ì ¸ì„œ ê·¸ë˜í”„ê°€ ê³¡ì„ í˜•ì— ê°€ê¹ê³  ë„ˆë¬´ í¬ê²Œ ì„¤ì •í•˜ë©´ ê³¼ì†Œì í•©ì˜ ìœ„í—˜ì´ ìˆë‹¤.
# > - ëŒ€ì—­í­ì´ ì‘ì„ ìˆ˜ë¡ ê°œë³„ ì»¤ë„ í•¨ìˆ˜ì˜ ì˜í–¥ë ¥ì´ ì»¤ì ¸ì„œ ê·¸ë˜í”„ê°€ ë¾°ì¡±í•´ì§€ê³  ë„ˆë¬´ ì‘ê²Œ ì„¤ì •í•˜ë©´ ê³¼ëŒ€ì í•©ì˜ ìœ„í—˜ì´ ìˆë‹¤.
# <img src="./images/mean_shift06.png" width="400" style="margin-left:10px">

# In[1]:


import pandas as pd

super_car_df = pd.read_csv('./datasets/super_car.csv')
super_car_df


# In[2]:


super_car_df.info()


# In[3]:


super_car_df = super_car_df.iloc[super_car_df[['Car Make', 'Car Model', 'Year']].drop_duplicates().index, :]
super_car_df = super_car_df.reset_index(drop=True)
super_car_df


# In[4]:


super_car_df.isna().sum()


# In[5]:


super_car_df['0-60 MPH Time (seconds)'] = super_car_df['0-60 MPH Time (seconds)'].apply(lambda x: x.replace('< ', ''))
super_car_df['0-60 MPH Time (seconds)'] = super_car_df['0-60 MPH Time (seconds)'].astype('float16')


# In[6]:


super_car_df['Price (in USD)'] = super_car_df['Price (in USD)'].apply(lambda x: x.replace(',', ''))
super_car_df['Price (in USD)'] = super_car_df['Price (in USD)'].astype('int32')


# In[7]:


super_car_df['Torque (lb-ft)'] = super_car_df['Torque (lb-ft)'].astype('int32')


# In[9]:


super_car_df['Horsepower'] = super_car_df['Horsepower'].apply(lambda x: x.replace('1000+', '1000'))
super_car_df['Horsepower'] = super_car_df['Horsepower'].apply(lambda x: x.replace(',', ''))
super_car_df['Horsepower'] = super_car_df['Horsepower'].astype('int16')


# In[10]:


super_car_df['Name'] = super_car_df['Car Make'] + ' ' + super_car_df['Car Model']
super_car_df = super_car_df.drop(columns=['Car Make', 'Car Model', 'Year'], axis=1)
super_car_df


# In[11]:


super_car_df = super_car_df.iloc[super_car_df.Name.drop_duplicates().index, :].reset_index(drop=True)
super_car_df


# In[12]:


super_car_df.info()


# In[13]:


super_car_df.isna().sum()


# In[14]:


super_car_df['Engine Size (L)'].value_counts()


# In[15]:


super_car_df['Engine Size (L)'] = super_car_df['Engine Size (L)'].fillna('Electric')
super_car_df.isna().sum()


# In[16]:


from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
super_car_df['Engine Size (L)'] = encoder.fit_transform(super_car_df['Engine Size (L)'])
print(encoder.classes_)


# In[17]:


import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(color_codes=True)

np.random.seed(124)
x = np.random.normal(0, 1, size=30)
print(x)
sns.kdeplot(x, bw_method=0.2, label='bw 0.2')
sns.kdeplot(x, label='bw 1')
sns.kdeplot(x, bw_method=2, label='bw 2')
plt.legend()


# In[18]:


super_car_df


# In[19]:


from sklearn.preprocessing import StandardScaler

scaled_super_car_df = StandardScaler().fit_transform(super_car_df.iloc[:, :-1])
scaled_super_car_df = pd.DataFrame(scaled_super_car_df, columns=super_car_df.iloc[:, :-1].columns)
scaled_super_car_df


# In[23]:


from sklearn.cluster import MeanShift

meanshift= MeanShift(bandwidth=1)
cluster_labels = meanshift.fit_predict(scaled_super_car_df)
# npì˜ uniqueëŠ” ì¤‘ë³µì—†ì´ ì„ íƒí•  ë•Œ ì‚¬ìš©í•œë‹¤.
print('cluster labels:', np.unique(cluster_labels))


# ##### estimate_bandwidth(input, quantile=0.3)
# - ë‚´ë¶€ì ìœ¼ë¡œ ìµœì ì˜ kernel bandwidthë¥¼ ì •í•˜ê¸° ìœ„í•´ KNN ê¸°ë²•ì„ ì´ìš©í•œë‹¤.
# - KNNì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ì˜ ê±´ìˆ˜ë¥¼ (ì „ì²´ ë°ì´í„° * quantile) ë¡œ ì •í•˜ê²Œ ë˜ë©°, ê°™ì€ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ë°ì´í„°ê°„ í‰ê·  ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ bandwidthë¥¼ ì •í•œë‹¤.
# - quantileì´ í¬ë©´ bandwidth ê°’ì´ ì»¤ì ¸ì„œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ê°€ ì‘ì•„ì§€ê³ , quantileì´ ì‘ìœ¼ë©´ bandwidth ê°’ì´ ì‘ì•„ì ¸ì„œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ê°€ ë§ì•„ì§„ë‹¤.
# - quantileì˜ ë²”ìœ„ëŠ” 0 ~ 1ì‚¬ì´ì´ë‹¤.

# In[24]:


from sklearn.cluster import estimate_bandwidth

bandwidth = estimate_bandwidth(scaled_super_car_df, quantile=0.5)
print('bandwidth ê°’:', round(bandwidth, 3))


# In[25]:


from sklearn.cluster import MeanShift

meanshift= MeanShift(bandwidth=2.246)
cluster_labels = meanshift.fit_predict(scaled_super_car_df)
print('cluster labels:', np.unique(cluster_labels))


# In[26]:


super_car_df['cluster'] = cluster_labels
super_car_df


# In[27]:


super_car_df.cluster.value_counts()


# In[28]:


### ì—¬ëŸ¬ê°œì˜ í´ëŸ¬ìŠ¤í„°ë§ ê°¯ìˆ˜ë¥¼ Listë¡œ ì…ë ¥ ë°›ì•„ ê°ê°ì˜ ì‹¤ë£¨ì—£ ê³„ìˆ˜ë¥¼ ë©´ì ìœ¼ë¡œ ì‹œê°í™”í•œ í•¨ìˆ˜ ì‘ì„±
import numpy as np
def visualize_silhouette(cluster_lists, X_features): 
    
    from sklearn.datasets import make_blobs
    from sklearn.cluster import KMeans
    from sklearn.metrics import silhouette_samples, silhouette_score

    import matplotlib.pyplot as plt
    import matplotlib.cm as cm
    import math
    
    # ì…ë ¥ê°’ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ê°¯ìˆ˜ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ì„œ, ê° ê°¯ìˆ˜ë³„ë¡œ í´ëŸ¬ìŠ¤í„°ë§ì„ ì ìš©í•˜ê³  ì‹¤ë£¨ì—£ ê°œìˆ˜ë¥¼ êµ¬í•¨
    n_cols = len(cluster_lists)
    
    # plt.subplots()ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ì— ê¸°ì¬ëœ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜ë§Œí¼ì˜ sub figuresë¥¼ ê°€ì§€ëŠ” axs ìƒì„± 
    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)
    
    # ë¦¬ìŠ¤íŠ¸ì— ê¸°ì¬ëœ í´ëŸ¬ìŠ¤í„°ë§ ê°¯ìˆ˜ë“¤ì„ ì°¨ë¡€ë¡œ iteration ìˆ˜í–‰í•˜ë©´ì„œ ì‹¤ë£¨ì—£ ê°œìˆ˜ ì‹œê°í™”
    for ind, n_cluster in enumerate(cluster_lists):
        
        # KMeans í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰í•˜ê³ , ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ì™€ ê°œë³„ ë°ì´í„°ì˜ ì‹¤ë£¨ì—£ ê°’ ê³„ì‚°. 
        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)
        cluster_labels = clusterer.fit_predict(X_features)
        
        sil_avg = silhouette_score(X_features, cluster_labels)
        sil_values = silhouette_samples(X_features, cluster_labels)
        
        y_lower = 10
        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\n' \
                          'Silhouette Score :' + str(round(sil_avg,3)) )
        axs[ind].set_xlabel("The silhouette coefficient values")
        axs[ind].set_ylabel("Cluster label")
        axs[ind].set_xlim([-0.1, 1])
        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])
        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks
        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])
        
        # í´ëŸ¬ìŠ¤í„°ë§ ê°¯ìˆ˜ë³„ë¡œ fill_betweenx( )í˜•íƒœì˜ ë§‰ëŒ€ ê·¸ë˜í”„ í‘œí˜„. 
        for i in range(n_cluster):
            ith_cluster_sil_values = sil_values[cluster_labels==i]
            ith_cluster_sil_values.sort()
            
            size_cluster_i = ith_cluster_sil_values.shape[0]
            y_upper = y_lower + size_cluster_i
            
            color = cm.nipy_spectral(float(i) / n_cluster)
            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \
                                facecolor=color, edgecolor=color, alpha=0.7)
            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
            y_lower = y_upper + 10
            
        axs[ind].axvline(x=sil_avg, color="red", linestyle="--")


# In[30]:


from sklearn.datasets import load_iris

visualize_silhouette([3, 4, 5, 7], scaled_super_car_df)


# In[29]:


fig, ax = plt.subplots(1, 3, figsize=(15, 4))
sns.scatterplot(x='Horsepower', y='Engine Size (L)', hue='cluster', data=super_car_df, ax=ax[0])
sns.scatterplot(x='Horsepower', y='Price (in USD)', hue='cluster', data=super_car_df, ax=ax[1])
sns.scatterplot(x='Torque (lb-ft)', y='Price (in USD)', hue='cluster', data=super_car_df, ax=ax[2])

