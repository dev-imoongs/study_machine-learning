#!/usr/bin/env python
# coding: utf-8

# ### Logistic Regression (ë¡œì§€ìŠ¤í‹± íšŒê·€)
# - ì„ í˜• íšŒê·€ ë°©ì‹ì„ ë¶„ë¥˜ì— ì ìš©í•œ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
# - ì„ í˜• í•¨ìˆ˜ì˜ íšŒê·€ ìµœì ì„ ì„ ì°¾ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì‹œê·¸ëª¨ì´ë“œ(sigmoid) í•¨ìˆ˜ì˜ ìµœì ì„ ì„ ì°¾ê³  ì´ í•¨ìˆ˜ì˜ ë°˜í™˜ê°’ì„ í™•ë¥ ë¡œ ê°„ì£¼í•˜ì—¬ í™•ë¥ ì— ë”°ë¼ ë¶„ë¥˜ë¥¼ ê²°ì •í•œë‹¤.
# - ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë‹¤ì¤‘ ë¶„ë¥˜ë„ ê°€ëŠ¥í•˜ì§€ë§Œ, ì£¼ë¡œ ì´ì§„ ë¶„ë¥˜ì— í™œìš©ë˜ë©°, ì˜ˆì¸¡ ê°’ì´ ì˜ˆì¸¡ í™•ë¥ ì´ë‹¤.
# - ë…ë¦½ë³€ìˆ˜ë¥¼ inputê°’ìœ¼ë¡œ ë°›ì•„ ì¢…ì†ë³€ìˆ˜ê°€ 1ì´ ë  í™•ë¥ ì„ ê²°ê³¼ê°’ìœ¼ë¡œ í•˜ëŠ” sigmoid í•¨ìˆ˜ë¥¼ ì°¾ëŠ” ê³¼ì •ì´ë‹¤.
# <img src="./images/sigmoid01.png" width="400" style="margin-left: 0">  
# 
# > ğŸ“Œ ì‹œê·¸ëª¨ì´ë“œ(sigmoid) í•¨ìˆ˜ëŠ” ì…ë ¥ ê°’ì„ ë„£ì—ˆì„ ë•Œ 1ì¼ í™•ë¥ ì€ ì–¼ë§ˆì¸ì§€ ì•Œì•„ë‚¼ ìˆ˜ ìˆë‹¤.  
# > ##### ë² ì´ì§€ì•ˆ ì¶”ë¡ ì„ í†µí•œ ì‹œê·¸ëª¨ì´ë“œ ì‹ ì¦ëª…  
# > - Bê°€ A<sub>1</sub> ì¡°ê±´ì— ì†í•  í™•ë¥ ì„ êµ¬í•œë‹¤.
# <img src="./images/sigmoid02.png" width="250" style="margin-top: -2px; margin-bottom:20px; margin-left: -20px">  
# > - ê° ë¶„ìì™€ ë¶„ëª¨ë¥¼ ë¶„ìë¡œ ë‚˜ëˆ ì¤€ë‹¤.
# > - ì•„ë˜ ë¡œê·¸ì˜ ì„±ì§ˆì„ ì´ìš©í•´ì„œ ìì—°ìƒìˆ˜ eë¥¼ ëŒ€ì…í•œë‹¤.
# <img src="./images/sigmoid03.png" width="100" style="margin-bottom:20px; margin-left: 0">  
# > - A/B = e<sup>-log(B/A)</sup>
# > - ì´ë¥¼ í†µí•´ ì•„ë˜ì˜ ì‹ì´ ë‚˜ì˜¨ë‹¤.
# <img src="./images/sigmoid04.png" width="250" style="margin-bottom:20px; margin-left: 0">  
# > - likelihood ratio(ìš°ë„): ì–´ë–¤ í˜„ìƒì´ ìˆì„ ë•Œ ê·¸ í˜„ìƒì´ ì–´ë–¤ ëª¨ì§‘ë‹¨ì— ì†í•  ê°€ëŠ¥ì„±ì„ ì˜ë¯¸í•œë‹¤.  
# > ì˜ˆë¥¼ ë“¤ì–´, 'ì–‘ì„±'íŒì •ì„ ë°›ì€ ëª¨ì§‘ë‹¨ì´ ìˆê³ , 'ì•”'ì´ë¼ëŠ” í˜„ìƒì´ ìˆê³ , 'ì•”ì´ ì•„ë‹˜'ì´ë¼ëŠ” í˜„ìƒì´ ìˆì„ ë•Œ 'ì•”'ì´ë¼ëŠ” í˜„ìƒì¼ ë•Œ 'ì–‘ì„±'ì´ë¼ëŠ” ëª¨ì§‘ë‹¨ì— ì†í•  ê°€ëŠ¥ì„±ì„ ìš°ë„ë¼ê³  í•œë‹¤.  
# ì•”ì— ê±¸ë¦° ì‚¬ëŒë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ì•” ì§„ë‹¨ìš© ì‹œì•½ìœ¼ë¡œ ê²€ì‚¬ë¥¼ í–ˆë”ë‹ˆ 99%ê°€ ì–‘ì„±ì¼ ê²½ìš° ìš°ë„ 99%ì´ë‹¤.
# > - P(C<sub>1</sub>|x) : ì¡°ê±´ë¶€ í™•ë¥ 
# > - P(x|C<sub>1</sub>) : ìš°ë„
# > - prior odds ratio: oddsë¥¼ í†µí•´ íŠ¹ì • í™•ë¥ ì„ ì—­ìœ¼ë¡œ ì•Œ ìˆ˜ ìˆë‹¤. ì¦‰, ê²½ê¸°ì—ì„œ ì§€ëŠ” í™•ë¥ ë§Œ ê°€ì§€ê³  oddsë¥¼ ì‚¬ìš©í•˜ì—¬ ì—­í™•ë¥ ì¸ ì´ê¸°ëŠ” í™•ë¥ ì„ êµ¬í•  ìˆ˜ ìˆë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤. ë‘ ê°€ì§€ ìƒí™©ì—ì„œì˜ í™•ë¥  ì¤‘ í•œ ê°€ì§€ ìƒí™©ì—ì„œëŠ” 0 ~ 1ì‚¬ì´ê°€ ë‚˜ì˜¤ì§€ë§Œ, ë°˜ëŒ€ ìƒí™©ì—ì„œëŠ” 1 ~ ë¬´í•œëŒ€ê°€ ë‚˜ì˜¤ë¯€ë¡œ ê· í˜•ì„ ë§ì¶”ê³ ì logë¥¼ ì”Œì›Œì¤€ë‹¤(ì´ë¥¼ logitì´ë¼ ë¶€ë¥¸ë‹¤).   
# logití•¨ìˆ˜ëŠ” 0ì—ì„œ 1ê¹Œì§€ì˜ í™•ë¥ ê°’ê³¼ -âˆì—ì„œ âˆ ì‚¬ì´ì˜ í™•ë¥ ê°’ì„ í‘œí˜„í•´ì£¼ëŠ” í•¨ìˆ˜ì´ë©°, ì‹œê·¸ëª¨ì´ë“œì˜ ì—­í•¨ìˆ˜ì´ë‹¤.  
# 
# - ğŸš© yì˜ ë²”ìœ„ëŠ” [0, 1]ì´ê³ , íŠ¹ì„±ê°’ xì˜ ë²”ìœ„ëŠ” [-âˆ, âˆ]ì´ë¯€ë¡œ ê´€ê³„ë¥¼ ë§í•  ìˆ˜ ì—†ì§€ë§Œ, logit ë³€í™˜ì€ [0, 1]ì˜ ë²”ìœ„ë¥¼ ê°€ì§€ëŠ” í™•ë¥ ì„ [-âˆ, âˆ]ë¡œ ë°”ê¿”ì£¼ê¸° ë•Œë¬¸ì—, ì˜ˆì¸¡ê°’(y)ê³¼ ì˜ˆì¸¡ê°’ì„ ë§Œë“¤ì–´ë‚´ëŠ” íŠ¹ì„±ê°’(x)ì˜ ê´€ê³„ë¥¼ ì„ í˜• ê´€ê³„(y = wx+b)ë¡œ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•œë‹¤.

# ##### LogisticRegression(penalty='l2', C=1.0, solver='lbfgs')
# - penalty: ì›í•˜ëŠ” ê·œì œë¥¼ ì„ íƒí•œë‹¤.
# - C: ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ê°’ì´ ì‘ì„ìˆ˜ë¡ ê·œì œê°€ ì‹¬í•´ì§€ê¸° ë•Œë¬¸ì— ë” ê°•ë ¥í•œ ì •ê·œí™”ê°€ ì§€ì •ëœë‹¤.
# - solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'}, default='lbfgs'  
# ìµœì í™” ë¬¸ì œì— ì‚¬ìš©í•  ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„° ì„¸íŠ¸ê°€ ì‘ì„ ê²½ìš° 'liblinear'ê°€ ì¢‹ê³ , í° ê²½ìš° 'sag'ì™€ 'saga'ê°€ ë” ì¢‹ë‹¤.  
# ë‹¤ì¤‘ ë¶„ë¥˜ëŠ” 'newton-cg', 'sag', 'saga' ë° 'lbfgs'ë§Œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë‹¤.  
# ì‚¬ìš© ê°€ëŠ¥í•œ ê·œì œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
# > - lbfgs[â€˜l2â€™, None]
# > - liblinear - [â€˜l1â€™, â€˜l2â€™]
# > - newton-cg - [â€˜l2â€™, None]
# > - newton-cholesky - [â€˜l2â€™, None]
# > - sag - [â€˜l2â€™, None]
# > - saga - [â€˜elasticnetâ€™, â€˜l1â€™, â€˜l2â€™, None] 

# In[2]:


import pandas as pd

corona_df = pd.read_csv('./datasets/corona.csv', low_memory=False)
corona_df.info()


# In[3]:


corona_df = corona_df[~corona_df['Cough_symptoms'].isna()]
corona_df = corona_df[~corona_df['Fever'].isna()]
corona_df = corona_df[~corona_df['Sore_throat'].isna()]
corona_df = corona_df[~corona_df['Headache'].isna()]
corona_df['Age_60_above'] = corona_df['Age_60_above'].fillna('No')
corona_df['Sex'] = corona_df['Sex'].fillna('unknown')
corona_df.isna().sum()


# In[4]:


corona_df['Target'] = corona_df['Corona']
corona_df.drop(columns='Corona', axis=1, inplace=True)
corona_df


# In[5]:


corona_df['Target'].value_counts()


# In[6]:


corona_df = corona_df[corona_df['Target'] != 'other']
corona_df['Target'].value_counts()


# In[7]:


from sklearn.preprocessing import LabelEncoder

columns = ['Cough_symptoms', 'Fever', 'Sore_throat', 'Shortness_of_breath', 'Headache', 'Age_60_above', 'Target']

for column in columns:
    encoder = LabelEncoder()
    targets = encoder.fit_transform(corona_df[column])
    corona_df.loc[:, column] = targets
    print(f'{column}_classes: {encoder.classes_}')


# In[8]:


corona_df = corona_df.drop(columns=['Ind_ID', 'Test_date', 'Sex', 'Known_contact'], axis=1)
corona_df


# In[9]:


corona_df = corona_df.reset_index(drop=True)
corona_df


# In[10]:


# ê° ì¹´í…Œê³ ë¦¬ ê°’ì„ ì •ìˆ˜ íƒ€ì…ìœ¼ë¡œ ë³€í™˜ !
corona_df = corona_df.astype('int16')
corona_df.info()


# In[11]:


from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix, ConfusionMatrixDisplay, f1_score, roc_auc_score
import matplotlib.pyplot as plt

# íƒ€ê²Ÿ ë°ì´í„°ì™€ ì˜ˆì¸¡ ê°ì²´ë¥¼ ì „ë‹¬ë°›ëŠ”ë‹¤.
def get_evaluation(y_test, prediction, classifier=None, X_test=None):
#     ì˜¤ì°¨ í–‰ë ¬
    confusion = confusion_matrix(y_test, prediction)
#     ì •í™•ë„
    accuracy = accuracy_score(y_test , prediction)
#     ì •ë°€ë„
    precision = precision_score(y_test , prediction)
#     ì¬í˜„ìœ¨
    recall = recall_score(y_test , prediction)
#     F1 score
    f1 = f1_score(y_test, prediction)
#     ROC-AUC
    roc_auc = roc_auc_score(y_test, prediction)

    print('ì˜¤ì°¨ í–‰ë ¬')
    print(confusion)
    print('ì •í™•ë„: {0:.4f}, ì •ë°€ë„: {1:.4f}, ì¬í˜„ìœ¨: {2:.4f}, F1:{3:.4f}, AUC:{4:.4f}'.format(accuracy , precision ,recall, f1, roc_auc))
    print("#" * 75)
    
    if classifier is not None and  X_test is not None:
        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,4))
        titles_options = [("Confusion matrix", None), ("Normalized confusion matrix", "true")]

        for (title, normalize), ax in zip(titles_options, axes.flatten()):
            disp = ConfusionMatrixDisplay.from_estimator(classifier, X_test, y_test, ax=ax, cmap=plt.cm.Blues, normalize=normalize)
            disp.ax_.set_title(title)
        plt.show()


# In[12]:


from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression

features, targets = corona_df.iloc[:,:-1], corona_df.Target

X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, stratify=targets, random_state=124)

smote = SMOTE(random_state=0)
X_train_over, y_train_over = smote.fit_resample(X_train, y_train)

lg = LogisticRegression(solver='liblinear', penalty='l2', random_state=124)
lg.fit(X_train_over, y_train_over)
prediction = lg.predict(X_test)


# In[13]:


get_evaluation(y_test, prediction, lg, X_test)


# In[14]:


def get_evaluation_by_thresholds(y_test, prediction_proba_class1, thresholds):
    
    for threshold in thresholds:
        binarizer = Binarizer(threshold=threshold).fit(prediction_proba_class1) 
        custom_prediction = binarizer.transform(prediction_proba_class1)
        print('ì„ê³„ê°’:', threshold)
        get_evaluation(y_test, custom_prediction)


# In[15]:


from sklearn.preprocessing import Binarizer
from sklearn.metrics import precision_recall_curve

prediction = lg.predict(X_test)
prediction_proba = lg.predict_proba(X_test)[:, 1].reshape(-1, 1)
precision, recall, thresholds = precision_recall_curve(y_test, prediction_proba)

get_evaluation_by_thresholds(y_test, prediction_proba, thresholds)


# In[16]:


prediction = Binarizer(threshold=0.6488399698426035).fit_transform(prediction_proba)
get_evaluation(y_test, prediction, lg, X_test)


# In[17]:


from sklearn.model_selection import train_test_split, GridSearchCV
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression

params = {'C': [0.001, 0.01, 0.1, 1, 10], 'solver': ['lbfgs', 'liblinear', 'saga']}

features, targets = corona_df.iloc[:,:-1], corona_df.Target

X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, stratify=targets, random_state=124)

smote = SMOTE(random_state=0)
X_train_over, y_train_over = smote.fit_resample(X_train, y_train)

grid_lg = GridSearchCV(LogisticRegression(max_iter=1000, penalty='l2', random_state=124), param_grid=params, cv=3, refit=True)
grid_lg.fit(X_train_over, y_train_over)
prediction = grid_lg.predict(X_test)


# In[18]:


# DataFrameìœ¼ë¡œ ë³€í™˜
scores_df = pd.DataFrame(grid_lg.cv_results_)
scores_df[['params', 'mean_test_score', 'rank_test_score', 
           'split0_test_score', 'split1_test_score', 'split2_test_score']].sort_values(by='rank_test_score')


# In[19]:


get_evaluation(y_test, prediction, grid_lg, X_test)


# In[20]:


from sklearn.preprocessing import Binarizer
from sklearn.metrics import precision_recall_curve

prediction = grid_lg.predict(X_test)
prediction_proba = grid_lg.predict_proba(X_test)[:, 1].reshape(-1, 1)
precision, recall, thresholds = precision_recall_curve(y_test, prediction_proba)

get_evaluation_by_thresholds(y_test, prediction_proba, thresholds)


# In[21]:


prediction = Binarizer(threshold=0.6541459441734264).fit_transform(prediction_proba)
get_evaluation(y_test, prediction, grid_lg, X_test)

