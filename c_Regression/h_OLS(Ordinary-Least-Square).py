#!/usr/bin/env python
# coding: utf-8

# ##### Ordinary Least Square(OSL)
# - ì„ í˜• íšŒê·€ ëª¨ë¸ì„ í‰ê°€í•˜ëŠ” ë° ìœ ìš©í•œ ë°©ë²•ì´ë©°, ëª¨ë¸ ì „ì²´ì™€ ëª¨ë¸ì˜ ê° featureì— ëŒ€í•œ í†µê³„ì  ì„±ëŠ¥ ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰ëœë‹¤.
# - ë‹¤ì–‘í•œ ìœ í˜•ì˜ í†µê³„ ëª¨ë¸ì„ ì¶”ì •í•˜ê³  ì—¬ëŸ¬ í†µê³„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì—¬ëŸ¬ í´ë˜ìŠ¤ì™€ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.
# - ê´€ì¸¡ëœ ë°ì´í„°ì— ì„ í˜• ë°©ì •ì‹ì„ ì ìš©í•˜ì—¬ ìƒì„±ë˜ë©°, ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ë²•ì´ë‹¤.
# - P>|t| (p-value): 0.05ë³´ë‹¤ ì‘ìœ¼ë©´ ë…ë¦½ ë³€ìˆ˜ê°€ ì¢…ì† ë³€ìˆ˜ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒì´ ìœ ì˜ë¯¸í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
# - Durbin-Watson: ë³´í†µ 1.5ì—ì„œ 2.5 ì‚¬ì´ì´ë©´ ë…ë¦½ìœ¼ë¡œ íŒë‹¨í•˜ê³  íšŒê·€ ëª¨í˜•ì´ ì í•©í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
# - ğŸš© ë‹¨, R<sup>2</sup> ê°’ì„ ìœ ì§€ ë˜ëŠ” ê°œì„ ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œë§Œ ìˆ˜í–‰í•œë‹¤.
# 
# ##### VIF(Variance Inflation Factor)
# - ë¶„ì‚° íŒ½ì°½ ìš”ì¸ ìˆ˜ì¹˜ê°€ 5 ë˜ëŠ” 10 ì´ìƒì¼ ê²½ìš° ë‹¤ì¤‘ ê³µì„ ì„±ì˜ ë¬¸ì œê°€ ìˆë‹¤ëŠ” ëœ»ì´ë‹¤.
# 
# ##### ë‹¤ì¤‘ ê³µì„ ì„±(Multicollinearity)
# - íšŒê·€ë¶„ì„ì—ì„œ ë…ë¦½ë³€ìˆ˜ë“¤ ê°„ì— ê°•í•œ ìƒê´€ê´€ê³„ê°€ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ì œë¥¼ ì˜ë¯¸í•œë‹¤.
# <img src="./images/multicollinearity.png" style="margin-left: 0">

# ##### ì‡¼í•‘ ê³ ê° ë°ì´í„°
# 
# - Customer ID: ê³ ê° ì•„ì´ë””
# - Gender: ê³ ê°ì˜ ì„±ë³„
# - Age: ê³ ê°ì˜ ë‚˜ì´
# - Annual Income: ê³ ê°ì˜ ì—°ì†Œë“
# - Spending Score: ê³ ê° í–‰ë™ ë° ì§€ì¶œ ì„±ê²©ì— ë”°ë¼ ìƒì ì—ì„œ í• ë‹¹í•œ ì ìˆ˜
# - Profession: ì§ì—…, ì „ë¬¸ì§
# - Work Experience: ê³ ê°ì˜ ê·¼ë¬´ ê²½ë ¥(ì—° ë‹¨ìœ„)
# - Family Size: ê°€ì¡± êµ¬ì„±ì› ìˆ˜

# In[2]:


import pandas as pd

customer_df = pd.read_csv('./datasets/customers.csv')
customer_df


# In[3]:


customer_df.isna().sum()


# In[4]:


customer_df.Profession.value_counts()


# In[5]:


customer_df = customer_df[~customer_df.Profession.isna()]
customer_df = customer_df.reset_index(drop=True)
customer_df.isna().sum()


# In[6]:


customer_df.duplicated().sum()


# In[7]:


customer_df = customer_df.drop(columns='CustomerID', axis=1)
customer_df


# In[8]:


customer_df['Score'] = customer_df['Spending Score (1-100)']
customer_df = customer_df.drop(columns='Spending Score (1-100)', axis=1)
customer_df


# In[9]:


from sklearn.preprocessing import LabelEncoder

encoders = []
columns = ['Gender', 'Profession']

for column in columns:
    encoder = LabelEncoder()
    encoded_feature = encoder.fit_transform(customer_df[column])
    customer_df[column] = encoded_feature
    print(encoder.classes_)
    encoders.append(encoder)


# In[10]:


import matplotlib.pyplot as plt
# conda install -c conda-forge seaborn   (0.12.2 ì´ìƒ)
import seaborn as sns

sns.pairplot(customer_df[['Gender', 'Age', 'Annual Income ($)', 'Profession', 'Work Experience', 'Family Size']])
plt.show()


# In[11]:


import statsmodels.api as sm
##### ì„±ë³„ê³¼ ê°€ì¡± êµ¬ì„±ì› ìˆ˜ê°€ ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤.
model = sm.OLS(customer_df[['Score']], customer_df[['Gender', 'Age', 'Annual Income ($)', 'Profession', 'Work Experience', 'Family Size']])
print(model.fit().summary())


# In[13]:


from statsmodels.stats.outliers_influence import variance_inflation_factor

def feature_engineering_VIF(features):
    vif = pd.DataFrame()
    vif['vif_score'] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]
    vif['feature'] = features.columns
    return vif


# In[14]:


print(feature_engineering_VIF(customer_df.iloc[:, :-1]))

