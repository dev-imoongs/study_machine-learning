#!/usr/bin/env python
# coding: utf-8

# ### Linear Regression (ë‹¨í•­ íšŒê·€)
# - ì•Œë ¤ì§„ ë°ì´í„° ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„°ì˜ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë°ì´í„° ë¶„ì„ ê¸°ë²•ì´ë‹¤.
# - ë…ë¦½ë³€ìˆ˜ëŠ” ì—¬ëŸ¬ê°œê°€ ë  ìˆ˜ ìˆê³  ì¢…ì†ë³€ìˆ˜ëŠ” í•˜ë‚˜ë§Œ ì˜¬ ìˆ˜ ìˆë‹¤.
# > ì˜ˆì‹œ
# > - ê³µë¶€ì‹œê°„(ë…ë¦½ë³€ìˆ˜)ì— ë”°ë¥¸ ì‹œí—˜ì ìˆ˜(ì¢…ì†ë³€ìˆ˜)
# > - ê¸°ì˜¨ê³¼ ìš”ì¼(ë…ë¦½ë³€ìˆ˜)ì— ë”°ë¥¸ í•´ìˆ˜ìš•ì¥ ì¸ì›(ì¢…ì†ë³€ìˆ˜)
# > - ì—­ì—ì„œì˜ ê±°ë¦¬, ì¡°ë§, ë²”ì£„ìœ¨(ë…ë¦½ë³€ìˆ˜)ì— ë”°ë¥¸ ë¶€ë™ì‚°ì‹œì„¸(ì¢…ì†ë³€ìˆ˜)
# 
# ##### LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)
# - fit_intercept: ì ˆí¸ì„ ê³„ì‚°í•  ê²ƒì¸ì§€ì˜ ì—¬ë¶€ë¥¼ ì§€ì •í•œë‹¤.
# - normalize: íšŒê·€ë¥¼ ìˆ˜í–‰í•˜ê¸° ì „ ì…ë ¥ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì •ê·œí™”í•  ì§€ì˜ ì—¬ë¶€ë¥¼ ì§€ì •í•œë‹¤.
# 
# ---
# 
# ### LinearRegression ê°ì²´ì˜ í•„ë“œ
# ##### coef_: ê¸°ìš¸ê¸°(ê°€ì¤‘ì¹˜)
# > - model.coef_ë¥¼ í†µí•´ ì„¤ëª…ë³€ìˆ˜ Xë¥¼ êµ¬ì„±í•˜ëŠ” ê° íŠ¹ì„±ë³„ ê°€ì¤‘ì¹˜ë¥¼ í™•ì¸
# > - íŠ¹ì • ì»¬ëŸ¼ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ê°’ì´ 0ì´ë¼ë©´ ê²°ê³¼ì— ì˜í–¥ì„ ì£¼ì§€ì•ŠëŠ” íŠ¹ì„±ì„
# > - íŠ¹ì • ì»¬ëŸ¼ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ê°’ì˜ ì ˆëŒ€ê°’ì´ ë†’ì„ìˆ˜ë¡ ì˜í–¥ë ¥ì´ í° íŠ¹ì„±ì„
# 
# ##### intercept_: ì ˆí¸(ìƒìˆ˜)
# 
# ##### score: ê²°ì • ê³„ìˆ˜ (R<sup>2</sup>)
# > - ëŒ€ìƒì„ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€ë¥¼ ìˆ«ìë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤.
# > - ê²°ì •ê³„ìˆ˜ëŠ” ìŒì˜ ê°’ë¶€í„° 1ê¹Œì§€ì˜ ë²”ìœ„ë¥¼ ê°€ì§€ëŠ” í‰ê°€ ê°’
# > - ê²°ì •ê³„ìˆ˜ ê°’ì´ ìŒìˆ˜ì¸ ê²½ìš° : ëª¨ë¸ì´ í‰ê·  ì •ë„ë„ ì˜ˆì¸¡í•˜ì§€ ëª»í•¨ì„ ì˜ë¯¸ (í•™ìŠµ ë¶€ì¡±)
# > - ê²°ì •ê³„ìˆ˜ ê°’ì´ 0ì¸ ê²½ìš° : ëª¨ë¸ì´ í‰ê·  ì •ë„ë¡œë§Œ ì˜ˆì¸¡í•¨ì„ ì˜ë¯¸ (í•™ìŠµ ë¶€ì¡±)
# > - ê²°ì •ê³„ìˆ˜ ê°’ì´ 1ì¸ ê²½ìš° : ëª¨ë¸ì´ ì‹¤ì œ ì •ë‹µê³¼ ì™„ë²½í•˜ê²Œ ë™ì¼í•˜ê²Œ ì˜ˆì¸¡í•¨ì„ ì˜ë¯¸ (ê³¼ëŒ€ì í•©)
# > - ê²°ì •ê³„ìˆ˜ê°’ì€ 0.7 ~ 0.8ì„ ëª©í‘œì¹˜ë¡œ ì„¤ì •í•œë‹¤.

# ##### 1ì¸ë‹¹ ê±´ê°• ë³´í—˜ ë¹„ìš©
# - age: 1ì°¨ ìˆ˜í˜œìì˜ ì—°ë ¹.
# - sex: ë³´í—˜ê³„ì•½ìì˜ ì„±ë³„(ì—¬ì„± ë˜ëŠ” ë‚¨ì„±).
# - bmi: ì²´ì§ˆëŸ‰ì§€ìˆ˜, í‚¤ ëŒ€ë¹„ ì²´ì¤‘ì„ ì¸¡ì •í•˜ëŠ” ì²™ë„.
# - children: ê±´ê°•ë³´í—˜ì˜ ì ìš©ì„ ë°›ëŠ” ìë…€ì˜ ìˆ˜ ë˜ëŠ” ë¶€ì–‘ê°€ì¡±ì˜ ìˆ˜.
# - smoker: í¡ì—° ìƒíƒœ(í¡ì—°ì ë˜ëŠ” ë¹„í¡ì—°ì).
# - region: ìˆ˜í˜œìì˜ ë¯¸êµ­ ë‚´ ê±°ì£¼ì§€ì—­(ë¶ë™, ë‚¨ë™, ë‚¨ì„œ, ë¶ì„œ).
# - charges: ê±´ê°•ë³´í—˜ì—ì„œ ì²­êµ¬í•˜ëŠ” ê°œì¸ë³„ ì˜ë£Œë¹„.

# In[123]:


import pandas as pd
medical_cost_df = pd.read_csv("./datasets/medical_cost.csv")
medical_cost_df


# In[124]:


medical_cost_df.shape


# In[125]:


medical_cost_df.info()


# In[126]:


medical_cost_df.describe().T


# In[127]:


medical_cost_df.isna().sum()


# In[128]:


medical_cost_df.duplicated().sum()


# In[129]:


medical_cost_df = medical_cost_df.drop_duplicates().reset_index(drop=True)
medical_cost_df.duplicated().sum()


# In[130]:


medical_cost_df.hist()


# In[131]:


import numpy as np
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(6, 2))
medical_cost_df.charges.hist(ax=axes[0], color='red')
np.log1p(medical_cost_df.charges).hist(ax=axes[1])


# In[132]:


import seaborn as sns
charges = medical_cost_df['charges'].groupby(medical_cost_df.region).sum().sort_values(ascending=True)
charges = charges.reset_index()
sns.barplot(x='region', y='charges', data=charges)


# In[133]:


sns.barplot(x='region', y='charges', hue='sex', data=medical_cost_df)


# In[134]:


sns.barplot(x = 'region', y = 'charges', hue='smoker', data=medical_cost_df)


# In[135]:


sns.barplot(x='region', y='charges', hue='children', data=medical_cost_df)


# #### ğŸš©ê²°ë¡ 
# ë‚¨ë™ë¶€ëŠ” í¡ì—°ìì— ëŒ€í•´ ê±´ê°•ë³´í—˜ë£Œê°€ ê°€ì¥ ë†’ê³  ê°€ì¥ ë‚®ì€ ê³³ì€ ë¶ë™ë¶€ì´ë‹¤. ë¶ë™ë¶€ ì‚¬ëŒë“¤ì´ ë‚¨ì„œë¶€ ì‚¬ëŒë“¤ì´ ë³´ë‹¤ ëœ í¡ì—°í•˜ì§€ë§Œ, ë‚¨ì„œë¶€ì™€ ë¶ì„œë¶€ ì‚¬ëŒë“¤ë³´ë‹¤ ì„±ë³„ì— ë”°ë¥¸ ìš”ê¸ˆì´ ë” ë†’ë‹¤. ê·¸ë¦¬ê³  ì•„ì´ê°€ 5ëª… ì´ìƒì¸ ì‚¬ëŒë“¤ì€ ì „ë°˜ì ìœ¼ë¡œ ì˜ë£Œë¹„ê°€ ë” ë‚®ì€ ê²½í–¥ì´ ìˆë‹¤.

# In[136]:


import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(12, 6))
sns.scatterplot(x = 'age', y = 'charges', data=medical_cost_df, hue='smoker', ax=axes[0])
sns.scatterplot(x = 'bmi', y = 'charges', data=medical_cost_df, hue='smoker', ax=axes[1])
sns.scatterplot(x = 'children', y = 'charges', data=medical_cost_df, hue='smoker', ax=axes[2])
plt.tight_layout(h_pad=0, w_pad=3)


# ##### ğŸš© ê²°ë¡ 
# ë‚˜ì´, ì²´ì§ˆëŸ‰, ì•„ì´ë“¤ì˜ ìˆ˜ê°€ ì¦ê°€í•¨ì—ë„ ë¶ˆêµ¬í•˜ê³  í¡ì—° ì—¬ë¶€ê°€ ì˜ë£Œë¹„ì— ê°€ì¥ ë†’ì€ ì˜í–¥ì„ ë¼ì¹œë‹¤. ë˜í•œ ì•„ì´ê°€ ìˆëŠ” ì‚¬ëŒë“¤ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹´ë°°ë¥¼ ëœ í”¼ìš´ë‹¤.

# In[137]:


from sklearn.preprocessing import LabelEncoder

columns = ['sex', 'smoker', 'region']
encoders = []

for column in columns:
    encode = LabelEncoder()
    encoded_feature = encode.fit_transform(medical_cost_df[column])
    medical_cost_df[column] = encoded_feature
    encoders.append(encode)
    print(encode.classes_)


# In[138]:


medical_cost_df.info()


# ##### ì¢…ì†ë³€ìˆ˜ y(íƒ€ê²Ÿ ë°ì´í„°)ë¥¼ ì •ê·œë¶„í¬í™” í•˜ê¸° ìœ„í•´ ë¡œê·¸ë¡œ ë³€í™˜í•˜ì—¬ í•™ìŠµì‹œí‚¨ë‹¤.

# In[139]:


import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

features, targets = medical_cost_df.iloc[:, :-1], medical_cost_df.charges

X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=124)

y_train = np.log1p(y_train)

linear_regression = LinearRegression()
linear_regression.fit(X_train, y_train)

# ê¸°ìš¸ê¸°(ê°€ì¤‘ì¹˜)
print(linear_regression.coef_)
# ì ˆí¸(ìƒìˆ˜)
print(linear_regression.intercept_)


# In[140]:


medical_cost_df.columns[linear_regression.coef_.argsort()[::-1]]


# ##### ì˜ˆì¸¡ ê°’ì€ ë¡œê·¸ ê°’ì´ê¸° ë•Œë¬¸ì— í´ë¼ì´ì–¸íŠ¸ì—ê²ŒëŠ” ì›ë˜ ê°’ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ë³´ì—¬ì¤˜ì•¼ í•œë‹¤.
# - ì§€ìˆ˜ë¡œ ë³€í™˜í•˜ë©´ ì›ë˜ ê°’ì˜ ê·¼ì‚¬ê°’(ê±°ì˜ ë™ì¼)ìœ¼ë¡œ ëŒì•„ê°„ë‹¤.

# In[141]:


np.expm1(linear_regression.predict(X_test))


# ##### R2-Score
# - ë¡œê·¸ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í›ˆë ¨ì‹œì¼°ë‹¤ë©´, ê·¸ ë¶„ì‚°ì— ë§ì¶° íšŒê·€ì„ ì´ ê·¸ì–´ì§„ë‹¤.
# - ì„±ëŠ¥ í‰ê°€ ì‹œ, ì‹¤ì œ ë°ì´í„°ë¡œ ë³€í™˜(ì§€ìˆ˜ë¥¼ ì·¨í•¨)í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ë©´ ê¸°ì¡´ íšŒê·€ì„ ì˜ ê¸°ì¤€ì¸ ë¶„í¬ì™€ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì—  
# (ì‹¤ì œ ë°ì´í„°ë¡œ ë³€í™˜í•˜ë©´, ë¡œê·¸ ê°’ì¼ ë•Œë³´ë‹¤ ë¶„ì‚°ë„ê°€ ë” ë†’ì•„ì§) R2-Scoreê°€ ë” ë‚®ê²Œ ë‚˜ì˜¤ê²Œ ëœë‹¤.

# In[142]:


# ë¬¸ì œ(X_test)ë¥¼ ì „ë‹¬í•´ì„œ ì˜ˆì¸¡í•œ ê°’ì€ ë¡œê·¸ê°’ì´ë‹¤.
prediction = linear_regression.predict(X_test)
# ì‹¤ì œ ì„±ëŠ¥ í‰ê°€ë¥¼ í•  ë•Œì—ë„ ì •ë‹µ(ì‹¤ì œ ê°’)ë„ ë¡œê·¸ë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤.
print(linear_regression.score(X_test, np.log1p(y_test)))
print(r2_score(np.log1p(y_test), prediction))


prediction = np.expm1(linear_regression.predict(X_test))
print(linear_regression.score(X_test, np.log1p(y_test)))
# ì˜ˆì¸¡í•œ ë¡œê·¸ê°’ì„ ì§€ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ 
print(r2_score(y_test, prediction))


# ##### ì‹¤ì œ ë°ì´í„°ë¡œ í›ˆë ¨í–ˆì„ ë•Œ(ë¡œê·¸ë¡œ ë³€í™˜í•˜ì§€ ì•Šì•˜ì„ ë•Œ)

# In[143]:


import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

features, targets = medical_cost_df.iloc[:, :-1], medical_cost_df.charges

X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=124)

# y_train = np.log1p(y_train)

linear_regression = LinearRegression()
linear_regression.fit(X_train, y_train)

# ê¸°ìš¸ê¸°(ê°€ì¤‘ì¹˜)
print(linear_regression.coef_)
# ì ˆí¸(ìƒìˆ˜)
print(linear_regression.intercept_)


# ##### ì‹¤ì œ ê°’ìœ¼ë¡œ í›ˆë ¨ì‹œí‚¨ ëª¨ë¸ì€ ì‹¤ì œ ê°’ìœ¼ë¡œ ê²€ì‚¬í•˜ë©´ ëœë‹¤.

# In[144]:


# ë¬¸ì œ(X_test)ë¥¼ ì „ë‹¬í•´ì„œ ì˜ˆì¸¡í•œ ê°’ì€ ë¡œê·¸ê°’ì´ë‹¤.
prediction = linear_regression.predict(X_test)
# ì‹¤ì œ ì„±ëŠ¥ í‰ê°€ë¥¼ í•  ë•Œì—ë„ ì •ë‹µ(ì‹¤ì œ ê°’)ë„ ë¡œê·¸ë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤.
print(linear_regression.score(X_test, y_test))
print(r2_score(y_test, prediction))


# ##### ğŸš©ê²°ë¡ : íƒ€ê²Ÿ(ì¢…ì† ë³€ìˆ˜ y) ë°ì´í„°ë¥¼ ë¨¼ì € í•™ìŠµì‹œí‚¤ê³ , ì •ê·œ ë¶„í¬í™”í•˜ì—¬ í•™ìŠµ ì‹œí‚¨ ë’¤ ë‘ ì ìˆ˜ë¥¼ ë¹„êµí•´ë³´ì!
