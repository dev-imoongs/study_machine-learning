#!/usr/bin/env python
# coding: utf-8

# ### ì´ìƒì¹˜ ì œê±°
# 
# #### Skewness(ì™œë„)
# - ë¶„í¬ì˜ ì •ê·œë¶„í¬ì™€ ë¹„êµí•˜ì—¬ ë¹„ëŒ€ì¹­ì„± ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì²™ë„ì´ë‹¤.
# - ì–‘ì˜ ê°’ì„ ê°€ì§€ë©´ (Positive Skewness, right skewed) - ì •ê·œ ë¶„í¬ë³´ë‹¤ ì˜¤ë¥¸ìª½ ê¼¬ë¦¬ê°€ ì™¼ìª½ë³´ë‹¤ ë” ê¸¸ ë•Œ.
# - ìŒì˜ ê°’ì„ ê°€ì§€ë©´ (Negative Skewness, left skewed) - ì •ê·œ ë¶„í¬ë³´ë‹¤ ì™¼ìª½ ê¼¬ë¦¬ê°€ ì˜¤ë¥¸ìª½ë³´ë‹¤ ë” ê¸¸ ë•Œ.
# <img src="./images/skewness01.png" width="400" style="margin-left: 0">
# <img src="./images/skewness02.png" width="400" style="margin-left: 0">
# - ex 1: skewness = 0.00 
# - ex 2: skewness = 0.00  
# - ex 3: skewness = 0.88
# - ex 4: skewness = -0.88 
# - ex 5: skewness = 3.02  
# - ex 6: skewness = -3.02
# 
# #### Kurtosis(ì²¨ë„)
# - ë°ì´í„°ê°€ í‰ê· ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê°€ê¹Œì´ ëª°ë ¤ ìˆì„ìˆ˜ë¡ ë¶„í¬ì˜ ì •ì ì€ ë”ìš± ë¾°ì¡±í•˜ë©°, ì´ ë¾°ì¡±í•œ ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì²™ë„ì´ë‹¤.
# <img src="./images/kurtosis.png" width="600" style="margin-left: 0">
# 
# 
# #### StandardScaler( )
# - ë°ì´í„°ì˜ í‰ê· ì„ 0, ë¶„ì‚°ì„ 1ì´ ë˜ë„ë¡, í‘œì¤€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ê²Œ í•˜ëŠ” ìŠ¤ì¼€ì¼ë§
# - Â±1.96ì„ ë²—ì–´ë‚˜ë©´ ì´ìƒì¹˜ë¡œ íŒë‹¨í•œë‹¤.
# - <code>from sklearn.processing import StandardScaler</code>
# 
# #### MinMaxScaler( )
# - ë°ì´í„°ê°€ 0~1 ì‚¬ì´ì— ìœ„ì¹˜í•˜ë„ë¡, ìµœì†Œê°’ì€ 0, ìµœëŒ€ê°’ì„ 1ë¡œ ë³€í™˜í•œë‹¤.
# - <code>from sklearn.processing import MinMaxScaler</code>
# 
# #### MaxAbsScaler( )
# - ëª¨ë“  ê°’ì„ -1~1 ì‚¬ì´ì— ìœ„ì¹˜í•˜ë„ë¡, ì ˆëŒ€ê°’ì˜ ìµœì†Œê°’ì€ 0, ìµœëŒ€ê°’ì€ 1ì´ ë˜ë„ë¡ ë³€í™˜í•œë‹¤.
# - <code>from sklearn.processing import MinAbsScaler</code>
# 
# #### ë¡œê·¸ë³€í™˜(Log transformation)
# - ì™œë„ì™€ ì²¨ë„ë¥¼ ê°€ì§„ ë³€ìˆ˜ë¥¼ ì •ê·œë¶„í¬ì— ê°€ê¹ê²Œ ë§Œë“¤ì–´ì¤€ë‹¤. í° ìˆ˜ì¹˜ë¥¼ ê°™ì€ ë¹„ìœ¨ì˜ ì‘ì€ ìˆ˜ì¹˜ë¡œ ë³€í™˜í•œë‹¤.
# - <code>np.log1p(df['col'])</code>
# - ì›ë˜ ê°’ìœ¼ë¡œ ì „í™˜í•˜ê³ ì í•  ë•Œ ì§€ìˆ˜ë¥¼ ì·¨í•´ì¤€ë‹¤.
# - <code>np.expm1(df['col'])</code>
# 
# ###### ğŸš©ì •ë¦¬1: íŠ¹ì • featureì˜ Skewê°€ ì‹¬í•˜ë©´ ë¡œê·¸ ë³€í™˜ì„ ì§„í–‰í•˜ê³ , ì „ì²´ì ìœ¼ë¡œ í‘œì¤€ ì •ê·œ ë¶„í¬ í˜•íƒœë¥¼ ë§ì¶”ê³  ì‹¶ìœ¼ë©´ Standard Scalerë¥¼ ì‚¬ìš©í•œë‹¤.  
# ###### ğŸš©ì •ë¦¬2: train/test ë¶„ë¦¬ ì „ì— ì „ì²´ ë³€ìˆ˜ë¥¼ ìŠ¤ì¼€ì¼ë§ í•˜ë©´ ì•ˆëœë‹¤.

# ### íƒ€ê²Ÿ ë°ì´í„° ì„¸íŠ¸ ë¶ˆê· í˜•
# 
# #### ì–¸ë” ìƒ˜í”Œë§(Under sampling)
# - ë¶ˆê· í˜•í•œ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë†’ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ë˜ í´ë˜ìŠ¤ì˜ ë°ì´í„° ìˆ˜ë¥¼ ì¤„ì„ìœ¼ë¡œì¨ ë°ì´í„° ë¶ˆê· í˜•ì„ í•´ì†Œí•œë‹¤.
# - í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ì „ì²´ ë°ì´í„° ìˆ˜ë¥¼ ê¸‰ê²©í•˜ê²Œ ê°ì†Œì‹œì¼œ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆë‹¤.
# <img src="./images/under_sampling.png" width="350" style="margin-left: 0">
# 
# #### ì˜¤ë²„ ìƒ˜í”Œë§(Over sampling)
# - ë¶ˆê· í˜•í•œ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë‚®ì€ ë¹„ìœ¨ í´ë˜ìŠ¤ì˜ ë°ì´í„° ìˆ˜ë¥¼ ëŠ˜ë¦¼ìœ¼ë¡œì¨ ë°ì´í„° ë¶ˆê· í˜•ì„ í•´ì†Œí•œë‹¤.
# - ì˜¤ë²„ ìƒ˜í”Œë§ì˜ ëŒ€í‘œì ì¸ ë°©ë²•ì—ëŠ” SMOTE(Synthetic Minority Over-sampling Technique)ê°€ ìˆë‹¤.
# <img src="./images/over_sampling.png" width="350" style="margin-left: 0">
# 
# ##### SMOT(Synthetic Minority Over-sampling Technique)
# - ë°˜ë“œì‹œ í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ë§Œ ì˜¤ë²„ ìƒ˜í”Œë§í•´ì•¼ í•œë‹¤.
# - ê²€ì¦ í˜¹ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì˜¤ë²„ ìƒ˜í”Œë§í•˜ëŠ” ê²½ìš° ì›ë³¸ ë°ì´í„°ê°€ ì•„ë‹Œ ë°ì´í„°ì—ì„œ ê²€ì¦ë˜ê¸° ë•Œë¬¸ì— ì˜¬ë°”ë¥¸ ê²€ì¦ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤.
# - ë‚®ì€ ë¹„ìœ¨ í´ë˜ìŠ¤ ë°ì´í„°ë“¤ì˜ ìµœê·¼ì ‘ ì´ì›ƒì„ ì´ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•œë‹¤.
# - ë™ì¼í•œ ë°ì´í„°ë¥¼ ë³µì œí•˜ëŠ” ê²ƒì€ ì˜ë¯¸ê°€ ì—†ê¸° ë•Œë¬¸ì— ì¼ì •í•œ ê±°ë¦¬ë¥¼ ë–¨ì–´ì§„ ìœ„ì¹˜ì— ë°ì´í„°ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•¨ì´ë‹¤.
# - ì˜¤ë²„ ìƒ˜í”Œë§ì„ í•˜ê²Œ ë˜ë©´ ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ë¹„ìœ¨ì´ ë†’ì•„ì§€ê¸° ë•Œë¬¸ì— ì •ë°€ë„ê°€ ê°ì†Œí•˜ê³  ì¬í˜„ìœ¨ì´ ì¦ê°€í•œë‹¤.
# - ì˜¤ë²„ ìƒ˜í”Œë§ì„ ì •í™•íˆ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” categoryíƒ€ì…ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒ ë³´ë‹¤ ì§ì ‘ ì¸ì½”ë”©ì„ í•´ì£¼ëŠ” ê²ƒì´ ì¢‹ë‹¤.
# - ğŸš© íšŒê·€ì²˜ëŸ¼ íƒ€ê²Ÿ ë°ì´í„°ê°€ ì—°ì†í˜• ë°ì´í„°ì¼ ê²½ìš° ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤(ìµœì†Œ ìƒ˜í”Œ ìˆ˜ê°€ 6ê°œ ì´ìƒì´ì—¬ì•¼ í•œë‹¤)
# <img src="./images/smote.png" width="650" style="margin-left: 0">

# In[33]:


import lightgbm

print(lightgbm.__version__)


# In[34]:


import pandas as pd

corona_df = pd.read_csv('./datasets/corona.csv', low_memory=False)
corona_df.info()


# In[35]:


corona_df = corona_df[~corona_df['Sore_throat'].isna()]
corona_df = corona_df[~corona_df['Headache'].isna()]
corona_df.isna().sum()


# In[36]:


corona_df['Target'] = corona_df['Corona']
corona_df.drop(columns='Corona', axis=1, inplace=True)
corona_df


# In[37]:


corona_df = corona_df[corona_df['Target'] != 'other']
corona_df['Target'].value_counts()


# In[38]:


corona_df = corona_df.drop(columns=['Ind_ID', 'Test_date', 'Sex', 'Known_contact', 'Age_60_above'], axis=1)
corona_df


# In[39]:


from sklearn.preprocessing import LabelEncoder

columns = ['Sore_throat', 'Shortness_of_breath', 'Headache', 'Target', 'Fever', 'Cough_symptoms']

for column in columns:
    encoder = LabelEncoder()
    targets = encoder.fit_transform(corona_df[column])
    corona_df.loc[:, column] = targets
    print(f'{column}_classes: {encoder.classes_}')


# In[40]:


corona_df = corona_df.reset_index(drop=True)
corona_df


# In[41]:


corona_df = corona_df.astype('int16')


# In[42]:


import time
from lightgbm import LGBMClassifier
from sklearn.model_selection import GridSearchCV, train_test_split
# conda install -c conda-forge imbalanced-learn
from imblearn.over_sampling import SMOTE

# GridSearchCV ìˆ˜í–‰ ì‹œì‘ ì‹œê°„ ì„¤ì •.
start_time = time.time()

param_grid = {
    'n_estimators': [50, 100, 500, 1000],
    'learning_rate': [0.3, 0.5, 0.7],
}

# boost_from_averageê°€ Trueì¼ ê²½ìš°(default: True) íƒ€ê²Ÿ ë°ì´í„°ê°€ ë¶ˆê· í˜• ë¶„í¬ë¥¼ ì´ë£¨ëŠ” ê²½ìš° ì¬í˜„ë¥  ë° ROC-AUC ì„±ëŠ¥ì´ ë§¤ìš° ì €í•˜ë¨
# ë”°ë¼ì„œ boost_from_averageë¥¼ Falseë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ìœ ë¦¬í•˜ë‹¤.
lgbm = LGBMClassifier(boost_from_average=False)

features, targets = corona_df.iloc[:, :-1], corona_df.Target

# í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(features, targets, stratify=targets, test_size=0.3)

# ì˜¤ë²„ ìƒ˜í”Œë§
# ê²€ì¦ ë°ì´í„°ë‚˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì•„ë‹Œ í•™ìŠµë°ì´í„°ì—ì„œë§Œ ì˜¤ë²„ìƒ˜í”Œë§ ì‚¬ìš©í•  ê²ƒ
smote = SMOTE(random_state=0)
X_train_over, y_train_over = smote.fit_resample(X_train, y_train)

print('SMOTE ì ìš© ì „:\n',pd.Series(y_train).value_counts() )
print('SMOTE ì ìš© í›„:\n',pd.Series(y_train_over).value_counts() )

# í•™ìŠµ ë°ì´í„°ë¥¼ ê²€ì¦ ë°ì´í„°ë¡œ ë¶„ë¦¬
X_val_train, X_val_test, y_val_train, y_val_test = train_test_split(X_train, y_train, stratify=y_train, test_size=0.5)

evals = [(X_val_train, y_val_train), (X_val_test, y_val_test)]

grid_lgbm = GridSearchCV(lgbm, param_grid, cv=3, refit=True, return_train_score=True, n_jobs=-1, error_score='raise')

grid_lgbm.fit(X_train_over, y_train_over, early_stopping_rounds=50, eval_set=evals)

print("GridSearchCV ìˆ˜í–‰ ì‹œê°„: {0:.1f} ì´ˆ ".format(time.time() - start_time))


# In[43]:


# DataFrameìœ¼ë¡œ ë³€í™˜
scores_df = pd.DataFrame(grid_lgbm.cv_results_)
scores_df[['params', 'mean_test_score', 'rank_test_score', 
           'split0_test_score', 'split1_test_score', 'split2_test_score']].sort_values(by='rank_test_score')


# In[44]:


from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix, ConfusionMatrixDisplay, f1_score, roc_auc_score
import matplotlib.pyplot as plt
# íƒ€ê²Ÿ ë°ì´í„°ì™€ ì˜ˆì¸¡ ê°ì²´ë¥¼ ì „ë‹¬ë°›ëŠ”ë‹¤.
def get_evaluation(y_test, prediction, classifier=None, X_test=None):
#     ì˜¤ì°¨ í–‰ë ¬
    confusion = confusion_matrix(y_test, prediction)
#     ì •í™•ë„
    accuracy = accuracy_score(y_test, prediction)
#     ì •ë°€ë„
    precision = precision_score(y_test, prediction)
#     ì¬í˜„ìœ¨
    recall = recall_score(y_test, prediction)
#     F1 score
    f1 = f1_score(y_test, prediction)
#     ROC-AUC
    roc_auc = roc_auc_score(y_test, prediction)

    print('ì˜¤ì°¨ í–‰ë ¬')
    print(confusion)
    print('ì •í™•ë„: {0:.4f}, ì •ë°€ë„: {1:.4f}, ì¬í˜„ìœ¨: {2:.4f}, F1:{3:.4f}, AUC:{4:.4f}'.format(accuracy , precision ,recall, f1, roc_auc))
    print("#" * 75)
    
    if classifier is not None and  X_test is not None:
        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,4))
        titles_options = [("Confusion matrix", None), ("Normalized confusion matrix", "true")]

        for (title, normalize), ax in zip(titles_options, axes.flatten()):
            disp = ConfusionMatrixDisplay.from_estimator(classifier, X_test, y_test, ax=ax, cmap=plt.cm.Blues)
            disp.ax_.set_title(title)
        plt.show()


# In[45]:


prediction = grid_lgbm.predict(X_test)
get_evaluation(y_test, prediction, grid_lgbm, X_test)


# In[46]:


from sklearn.inspection import permutation_importance

importance = permutation_importance(grid_lgbm, X_test, y_test, n_repeats=100, random_state=0)
corona_df.columns[importance.importances_mean.argsort()[::-1]]


# In[48]:


from sklearn.preprocessing import Binarizer

def get_evaluation_by_thresholds(y_test, prediction_proba_class1, thresholds):
    for threshold in thresholds:
        binarizer = Binarizer(threshold=threshold).fit(prediction_proba_class1) 
        custom_prediction = binarizer.transform(prediction_proba_class1)
        print('ì„ê³—ê°’:', threshold)
        get_evaluation(y_test, custom_prediction, prediction_proba_class1)


# In[49]:


import numpy as np
from sklearn.preprocessing import Binarizer
from sklearn.metrics import precision_recall_curve

prediction_proba_class1 = grid_lgbm.predict_proba(X_test)[:, 1].reshape(-1, 1)

# precision, recall, thresholds = precision_recall_curve(y_test, prediction_proba_class1, pos_label="positive")
thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
get_evaluation_by_thresholds(y_test, prediction_proba_class1, thresholds)


# In[ ]:


ì˜¤ì°¨ í–‰ë ¬
[[48800  3202]
 [ 1522  1417]]
ì •í™•ë„: 0.9140, ì •ë°€ë„: 0.3068, ì¬í˜„ìœ¨: 0.4821, F1:0.3750, AUC:0.7636
###########################################################################


# In[50]:


from sklearn.preprocessing import Binarizer
prediction = Binarizer(threshold=0.7).fit_transform(prediction_proba_class1)
get_evaluation(y_test, prediction, prediction_proba_class1)

