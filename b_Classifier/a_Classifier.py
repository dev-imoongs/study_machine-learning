#!/usr/bin/env python
# coding: utf-8

# ### ë¶„ë¥˜(Classifier)
# - ëŒ€í‘œì ì¸ ì§€ë„í•™ìŠµ ë°©ë²• ì¤‘ í•˜ë‚˜ì´ë©°, ë‹¤ì–‘í•œ ë¬¸ì œì™€ ì •ë‹µì„ í•™ìŠµí•œ ë’¤ ë³„ë„ì˜ í…ŒìŠ¤íŠ¸ì—ì„œ ì •ë‹µì„ ì˜ˆì¸¡í•œë‹¤.
# - ì£¼ì–´ì§„ ë¬¸ì œë¥¼ ë¨¼ì € í•™ìŠµí•œ ë’¤ ìƒˆë¡œìš´ ë¬¸ì œì— ëŒ€í•œ ì •ë‹µì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ì´ë‹¤.
# - ì´ì§„ë¶„ë¥˜(Binary Classification)ì˜ ê²½ìš° ì •ë‹µì€ 0(ìŒì„±, Negative)ê³¼ 1(ì–‘ì„±, Positive)ê³¼ ê°™ì´ True, Falseê°’ì„ ê°€ì§„ë‹¤.  
# <div style="width:500px; height:200px; display: flex; margin-top: 25px; margin-bottom: 25px; margin-left: 0px;">
#     <div>
#         <img src="./images/classifier01.png" width="200">  
#     </div>
#     <div style="width: 200px; heigth: 100px; margin-top: 25px; margin-left: 30px;">
#         <img src="./images/classifier02.png">  
#     </div>
# </div>
# - ë‹¤ì¤‘ ë¶„ë¥˜(Multiclass Classification)ëŠ” ì •ë‹µì´ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê°’ì€ 3ê°œ ì´ìƒì´ë‹¤(ì˜ˆ: 0, 1, 2).  
# <img src="./images/classifier03.png" width="300" style="margin-top: 25px; margin-left: 0px;"> 

# ###  ğŸ“Œìš©ì–´ ì •ë¦¬
# ##### í”¼ì²˜(Feature)
# - ë°ì´í„° ì„¸íŠ¸ì˜ ì¼ë°˜ ì»¬ëŸ¼ì´ë©°, 2ì°¨ì› ì´ìƒì˜ ë‹¤ì°¨ì› ë°ì´í„°ê¹Œì§€ í†µí‹€ì–´ í”¼ì²˜ë¼ê³  í•œë‹¤.
# - íƒ€ê²Ÿì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì†ì„±ì„ ì˜ë¯¸í•œë‹¤.
# ##### ë ˆì´ë¸”(Label), í´ë˜ìŠ¤(Class), íƒ€ê²Ÿ(Target), ê²°ì •(Decision)
# - ì§€ë„ í•™ìŠµ ì‹œ ë°ì´í„°ì˜ í•™ìŠµì„ ìœ„í•´ ì£¼ì–´ì§€ëŠ” ì •ë‹µì„ ì˜ë¯¸í•œë‹¤.
# - ì§€ë„ í•™ìŠµ ì¤‘, ë¶„ë¥˜ì˜ ê²½ìš° ì´ë¥¼ ë ˆì´ë¸” ë˜ëŠ” í´ë˜ìŠ¤ë¼ê³ ë„ ë¶€ë¥¸ë‹¤.
# 
# <img src="./images/feature_target.png" width="450" style="margin-left: 0">

# ### ë¶„ë¥˜ ì˜ˆì¸¡ í”„ë¡œì„¸ìŠ¤
# <img src="./images/classifier_flow.png">

# ### ë¶“ê½ƒ í’ˆì¢… ì˜ˆì¸¡
# - ë‹¤ì¤‘ ë¶„ë¥˜(Multiclass Classification)
# ##### Featuer
# - sepal length : ê½ƒë°›ì¹¨ì˜ ê¸¸ì´
# - sepal width : ê½ƒë°›ì¹¨ì˜ ë„ˆë¹„
# - petal length : ê½ƒìì˜ ê¸¸ì´
# - petal width: ê½ƒìì˜ ë„ˆë¹„
# 
# ##### Target(Label)
# - 0 : Setosa
# - 1 : Vesicolor
# - 2 : Virginica

# In[4]:


import sklearn
print(sklearn.__version__)


# In[5]:


# ì‚¬ì´í‚·ëŸ° ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë‚´ì¥ëœ iris(ë¶“ê½ƒ) ë°ì´í„°
from sklearn.datasets import load_iris
# ê²°ì • íŠ¸ë¦¬ ëª¨ë¸
from sklearn.tree import DecisionTreeClassifier
# í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶„ë¦¬í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split


# ### ë¶“ê½ƒ ë°ì´í„° ì •ë¦¬
# ##### í‚¤ëŠ” ë³´í†µ data, target, target_name, feature_names, DESCRë¡œ êµ¬ì„±ëœë‹¤.
# - dataëŠ” featureì˜ ë°ì´í„° ì„¸íŠ¸ì´ë‹¤.
# - targetì€ ë ˆì´ë¸” ê°’ì´ë‹¤.
# - target_namesëŠ” ê° ë ˆì´ë¸”ì˜ ì´ë¦„ì´ë‹¤.
# - feature_namesëŠ” featureì˜ ì´ë¦„ì´ë‹¤.
# - DESCRì€ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ì„¤ëª…ê³¼ ê° featureì˜ ì„¤ëª…ì´ë‹¤.

# In[6]:


import pandas as pd

# ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
iris = load_iris()

# ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ì˜ keyê°’
print(f'ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ì˜ í‚¤ {iris.keys()}')

keys = pd.DataFrame(iris.keys()).rename(columns={0: 'key'}).T
display(keys)

# iris.dataëŠ” feature ë°ì´í„°ì´ë©°, numpy.ndarrayì´ë‹¤.
iris_feature = iris.data
print(f'iris feature: {iris_feature[:5]}')
print(f'iris type: {type(iris_feature[:5])}')
print(f'iris feature name: {iris.feature_names}')

print("=" * 80)

# iris.targetì€ ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ì—ì„œ íƒ€ê²Ÿ(ë ˆì´ë¸”, ê²°ì • ê°’) ë°ì´í„°ë¥¼ numpy.ndarrayë¡œ ê°€ì§€ê³  ìˆë‹¤.
iris_target = iris.target
print(f'iris target: {iris_target[:5]}')
print(f'iris type: {type(iris_target[:5])}')
print(f'iris target name: {iris.target_names}')

# ë¶“ê½ƒ ë°ì´í„° ì„¸íŠ¸ DataFrameìœ¼ë¡œ ë³€í™˜í•œë‹¤.
iris_df = pd.DataFrame(data=iris_feature, columns=iris.feature_names)
iris_df['target'] = iris_target
display(iris_df.head())
print(iris_df.info())


# In[11]:


iris


# ### ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬
# ##### train_test_split(feature, target, test_size, random_state )
# - í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ ë¶„ë¦¬
# - feature: ì „ì²´ ë°ì´í„° ì„¸íŠ¸ ì¤‘ feature
# - target: ì „ì²´ ë°ì´í„° ì„¸íŠ¸ ì¤‘ target
# - test_size: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ë¹„ìœ¨(0~1)
# - random_state: ë§¤ë²ˆ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì›í•  ë•Œ, ì›í•˜ëŠ” Seedê°’ ì‘ì„±

# In[4]:


import numpy as np

X_train, X_test, y_train, y_test = train_test_split(iris_feature, iris_target, test_size=0.2, random_state=124)

print(type(X_train), type(X_test), type(y_train), type(y_test))
print(X_train[:5], X_test[:5], y_train[:5], y_test[:5], sep="\n======================\n")
print(f'ì „ì²´ ë°ì´í„° ì„¸íŠ¸ ê°œìˆ˜: {iris_feature.__len__()}')
print(f'í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ ê°œìˆ˜: {X_train.__len__()}')
print(f'íƒ€ê²Ÿ ë°ì´í„° ì„¸íŠ¸ ê°œìˆ˜: {X_test.__len__()}')


# ##### train_test_split(feature, target, test_size, random_state)
# - DataFrameê³¼ Seriesë„ ë¶„í• ì´ ê°€ëŠ¥í•˜ë‹¤.

# In[5]:


import pandas as pd

iris_df = pd.DataFrame(iris_feature, columns=iris.feature_names)
iris_df['target'] = iris_target
iris_df.head()


# In[10]:


feature_df = iris_df.iloc[:, :-1]
target_df = iris_df.loc[:, 'target']

display(feature_df.head())
display(target_df.head())


# In[18]:


X_train, X_test, y_train, y_test = train_test_split(feature_df, target_df, test_size=0.5, random_state=124)

print(X_train[:5], X_test[:5], y_train[:5], y_test[:5], sep="\n")
print(f'ì „ì²´ ë°ì´í„° ì„¸íŠ¸ ê°œìˆ˜: {iris_feature.__len__()}')
print(f'í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ ê°œìˆ˜: {X_train.__len__()}')
print(f'íƒ€ê²Ÿ ë°ì´í„° ì„¸íŠ¸ ê°œìˆ˜: {X_test.__len__()}')


# ### ëª¨ë¸ í•™ìŠµ
# ##### fit(train_feature, train_target)
# - ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë•Œ ì‚¬ìš©í•œë‹¤.
# - train_feature: í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ ì¤‘ feature
# - train_target: í›ˆë ¨ ë°ì´í„° ì„¸íŠ¸ ì¤‘ target

# In[19]:


# DecisionTreeClassifier ê°ì²´ ìƒì„±
decision_tree_classifier = DecisionTreeClassifier()

# ëª¨ë¸ í•™ìŠµ ìˆ˜í–‰
decision_tree_classifier.fit(X_train, y_train)


# ### ì˜ˆì¸¡ ìˆ˜í–‰
# ##### predict(test_feature)
# - í•™ìŠµëœ ëª¨ë¸ì— í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ì˜ featureë¥¼ ì „ë‹¬í•˜ì—¬ targetì„ ì˜ˆì¸¡í•œë‹¤.
# - test_feature: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ ì¤‘ feature

# In[20]:


prediction = decision_tree_classfier.predict(X_test)
print(prediction)


# ### ì •í™•ë„
# ##### accuracy_score(test_target, prediction)
# - ëª¨ë¸ì˜ ì˜ˆì¸¡ ì •í™•ë„(Accuracy)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ë¥ ì„ êµ¬í•˜ì—¬ í‰ê°€í•  ìˆ˜ ìˆë‹¤.

# In[21]:


from sklearn.metrics import accuracy_score
print(f"ì˜ˆì¸¡ ì •í™•ë„: {accuracy_score(y_test, prediction)}")

