#!/usr/bin/env python
# coding: utf-8

# ### Naive Bayes Classifier Task
# ### ë¬¸ì¥ì—ì„œ ëŠê»´ì§€ëŠ” ê°ì • ì˜ˆì¸¡
# ##### ë‹¤ì¤‘ ë¶„ë¥˜(Multiclass Classification)
# - ë¹„ëŒ€ë©´ ì‹¬ë¦¬ ìƒë‹´ì‚¬ë¡œì„œ ë©”ì„¸ì§€ë¥¼ ì „ë‹¬í•œ í™˜ìì— ëŒ€í•œ ê°ì • ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆë‹¤.
# - ê° ë©”ì„¸ì§€ ë³„ë¡œ ê°ì •ì´ í‘œì‹œë˜ì–´ ìˆë‹¤.
# - ë¯¸ë˜ì— ë™ì¼í•œ ë©”ì„¸ì§€ë¥¼ ë³´ë‚´ëŠ” í™˜ìì—ê²Œ ì–´ë–¤ ì‹¬ë¦¬ ì¹˜ë£Œê°€ ì í•©í•  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•œ ëª¨ë¸ì„ êµ¬ì¶•í•œë‹¤.
# 
# ##### ğŸš©ì œì‹œëœ featureì˜ targetì„ ì˜ˆì¸¡í•´ë³´ì!
# - 'Sweat deer'  
# - 'The moment I saw her, I realized something was wrong.'

# In[1]:


import pandas as pd

feeling_df = pd.read_csv('./datasets/feeling.csv', sep=";")
feeling_df


# ##### ë ˆì´ë¸” ì¸ì½”ë”©

# In[2]:


from sklearn.preprocessing import LabelEncoder

feeling_encoder = LabelEncoder()
feeling_df['target'] = feeling_encoder.fit_transform(feeling_df.feeling)


# In[3]:


print(feeling_encoder.classes_)
feeling_df


# ##### íƒ€ê²Ÿ ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ

# In[4]:


feeling_df.target.value_counts()

# ['anger' 'fear' 'joy' 'love' 'sadness' 'surprise']
anger = feeling_df[feeling_df.target == 0].sample(653)
fear = feeling_df[feeling_df.target == 1].sample(653)
joy = feeling_df[feeling_df.target == 2].sample(653)
love = feeling_df[feeling_df.target == 3].sample(653)
sadness = feeling_df[feeling_df.target == 4].sample(653)
surprise = feeling_df[feeling_df.target == 5]

feeling_df = pd.concat([anger, fear, joy, love, sadness, surprise])


# In[5]:


feeling_df.target.value_counts()


# In[6]:


from sklearn.model_selection import train_test_split

features, targets = feeling_df.message, feeling_df.target

X_train, X_test, y_train, y_test = train_test_split(features, targets, stratify=targets, test_size=0.2)


# In[7]:


from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline

naive_bayes_pipeline = Pipeline([('count_vectorizer', CountVectorizer()), ('multinomialNB', MultinomialNB())])
naive_bayes_pipeline.fit(X_train, y_train)


# In[8]:


prediction = naive_bayes_pipeline.predict(X_test)
prediction


# In[9]:


naive_bayes_pipeline.score(X_test, y_test)


# In[10]:


from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix, ConfusionMatrixDisplay, f1_score, roc_auc_score
import matplotlib.pyplot as plt
# íƒ€ê²Ÿ ë°ì´í„°ì™€ ì˜ˆì¸¡ ê°ì²´ë¥¼ ì „ë‹¬ë°›ëŠ”ë‹¤.
def get_evaluation(y_test, prediction, classifier=None, X_test=None):
#     ì˜¤ì°¨ í–‰ë ¬
    confusion = confusion_matrix(y_test, prediction)
#     ì •í™•ë„
    accuracy = accuracy_score(y_test , prediction)
#     ì •ë°€ë„
    precision = precision_score(y_test , prediction, average='macro')
#     ì¬í˜„ìœ¨
    recall = recall_score(y_test , prediction, average='macro')
#     F1 score
    f1 = f1_score(y_test, prediction, average='macro')
#     ROC-AUC : ì—°êµ¬ ëŒ€ìƒ
#     roc_auc = roc_auc_score(y_test, prediction)

    print('ì˜¤ì°¨ í–‰ë ¬')
    print(confusion)
    print('ì •í™•ë„: {0:.4f}, ì •ë°€ë„: {1:.4f}, ì¬í˜„ìœ¨: {2:.4f}, F1:{3:.4f}'.format(accuracy , precision ,recall, f1))
    print("#" * 75)
    
    if classifier is not None and  X_test is not None:
        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,4))
        titles_options = [("Confusion matrix", None), ("Normalized confusion matrix", "true")]

        for (title, normalize), ax in zip(titles_options, axes.flatten()):
            disp = ConfusionMatrixDisplay.from_estimator(classifier, X_test, y_test, ax=ax, cmap=plt.cm.Blues, normalize=normalize)
            disp.ax_.set_title(title)
        plt.show()


# In[11]:


get_evaluation(y_test, prediction, naive_bayes_pipeline, X_test)

